{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60abf500",
   "metadata": {},
   "source": [
    "# Neural Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35178618",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b45751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Embedding, Dense, Concatenate, Multiply, Flatten, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "big_df    = pd.read_csv('data/big_matrix.csv')\n",
    "small_df  = pd.read_csv('data/small_matrix.csv')\n",
    "item_cat  = pd.read_csv('data/item_categories.csv')\n",
    "user_feat = pd.read_csv('data/user_features.csv')\n",
    "item_daily_features = pd.read_csv('data/item_daily_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca41c69",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f5c73",
   "metadata": {},
   "source": [
    "Note : Popularity is used for the evaluation of the model. It is not used in the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8da85059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights:\n",
      "play_cnt         3.653623e-08\n",
      "show_cnt        -5.446159e-08\n",
      "like_user_num   -9.252525e-08\n",
      "comment_cnt     -1.097558e-07\n",
      "share_cnt       -2.289058e-06\n",
      "dtype: float64\n",
      "count    10728.000000\n",
      "mean         1.203716\n",
      "std          0.175478\n",
      "min         -2.678407\n",
      "25%          1.235405\n",
      "50%          1.269730\n",
      "75%          1.272172\n",
      "max          1.276259\n",
      "Name: popularity_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "pop = item_daily_features.groupby(\"video_id\")[[\n",
    "    'show_cnt', 'play_cnt', 'like_user_num', 'share_cnt', 'comment_cnt',\n",
    "]].sum()\n",
    "\n",
    "video_watch_ratio = big_df.groupby(\"video_id\")['watch_ratio'].mean()\n",
    "pop = pop.join(video_watch_ratio, on=\"video_id\",how=\"right\")\n",
    "X = pop[['show_cnt', 'play_cnt', 'like_user_num', 'share_cnt', 'comment_cnt']].fillna(0)\n",
    "y = pop['watch_ratio'].fillna(0)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "coeffs = pd.Series(model.coef_, index=X.columns)\n",
    "print(\"Learned weights:\")\n",
    "print(coeffs.sort_values(ascending=False))\n",
    "pop['popularity_score'] = model.predict(X)\n",
    "pop = pop['popularity_score']\n",
    "pop_df = pop.reset_index()\n",
    "pop_df.columns = ['video_id', 'popularity_score']\n",
    "pop_df = pop_df.dropna(subset=['video_id'])\n",
    "pop_df['video_id'] = pop_df['video_id'].astype('int32')\n",
    "print(pop_df['popularity_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode tags (0-30) → multi-hot vector\n",
    "item_cat['feat'] = item_cat['feat'].apply(literal_eval)\n",
    "mlb = MultiLabelBinarizer(classes=list(range(31)))\n",
    "tag_matrix = mlb.fit_transform(item_cat['feat'])\n",
    "tag_df = pd.DataFrame(tag_matrix, columns=[f'tag_{i}' for i in mlb.classes_])\n",
    "item_cat = pd.concat([item_cat[['video_id']], tag_df], axis=1)\n",
    "\n",
    "# Encode any string user features to integer codes\n",
    "for col in user_feat.columns:\n",
    "    if col != 'user_id' and user_feat[col].dtype == 'object':\n",
    "        user_feat[col], _ = pd.factorize(user_feat[col])\n",
    "\n",
    "# Merge: train on big_matrix, test on small_matrix\n",
    "df_train = big_df.merge(item_cat, on='video_id').merge(user_feat, on='user_id').merge(pop_df, on='video_id')\n",
    "df_test = small_df.merge(item_cat, on='video_id').merge(user_feat, on='user_id').merge(pop_df, on='video_id')\n",
    "\n",
    "# Number of videos watched by each user\n",
    "user_inter_counts = df_train.groupby(\"user_id\")[\"video_id\"].count()\n",
    "user_inter_counts.name = \"User Interactions\"\n",
    "\n",
    "# Number of times each video has been watched\n",
    "video_inter_counts = df_train.groupby(\"video_id\")[\"user_id\"].count()\n",
    "video_inter_counts.name = \"Video Interactions\"\n",
    "big_watch_ratio = df_train.watch_ratio\n",
    "\n",
    "df_train = df_train[\n",
    "    (df_train['user_id'].isin(user_inter_counts[user_inter_counts >= 248].index)) &\n",
    "    (df_train['video_id'].isin(video_inter_counts[video_inter_counts >= 1].index)) &\n",
    "    (df_train['watch_ratio'] > 0) &\n",
    "    (df_train['watch_ratio'] <= big_watch_ratio.quantile(0.75))\n",
    "]\n",
    "\n",
    "df_train['watch_ratio_log'] = np.log1p(df_train['watch_ratio'])\n",
    "df_test['watch_ratio_log'] = np.log1p(df_test['watch_ratio'])\n",
    "\n",
    "# Build tag_multi_hot list column and cast types\n",
    "tag_cols = [f'tag_{i}' for i in range(31)]\n",
    "for df in (df_train, df_test):\n",
    "    df['tag_multi_hot'] = df[tag_cols].values.tolist()\n",
    "    df.fillna(0, inplace=True)\n",
    "    df['user_id'] = df['user_id'].astype('int32')\n",
    "    df['video_id'] = df['video_id'].astype('int32')\n",
    "    for col in user_feat.columns:\n",
    "        if col != 'user_id':\n",
    "            df[col] = df[col].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446d860",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tf.data Dataset\n",
    "def df_to_dataset(df, shuffle=False, batch_size=1024):\n",
    "    labels = df['watch_ratio_log'].values.astype('float32')\n",
    "    inputs = {col: df[col].values for col in ['user_id','video_id'] + [c for c in user_feat.columns if c!='user_id']}\n",
    "    inputs['tag_multi_hot'] = np.array(df['tag_multi_hot'].tolist(), dtype='float32')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(labels))\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = df_to_dataset(df_train, shuffle=True)\n",
    "test_ds  = df_to_dataset(df_test)\n",
    "\n",
    "# Determine global vocab sizes\n",
    "vocab = {}\n",
    "for col in ['user_id','video_id'] + [c for c in user_feat.columns if c!='user_id']:\n",
    "    mx = max(df_train[col].max(), df_test[col].max())\n",
    "    vocab[col] = int(mx) + 1\n",
    "\n",
    "K = 64; tag_dim = 16; user_feat_dim = 8\n",
    "\n",
    "# Inputs\n",
    "u_in = Input(shape=(), name='user_id', dtype='int32')\n",
    "i_in = Input(shape=(), name='video_id', dtype='int32')\n",
    "t_in = Input(shape=(31,), name='tag_multi_hot', dtype='float32')\n",
    "uf_ins = [Input(shape=(), name=col, dtype='int32') \n",
    "          for col in user_feat.columns if col!='user_id']\n",
    "\n",
    "# Embeddings\n",
    "u_emb = Flatten()(Embedding(input_dim=vocab['user_id'], output_dim=K)(u_in))\n",
    "i_emb = Flatten()(Embedding(input_dim=vocab['video_id'], output_dim=K)(i_in))\n",
    "\n",
    "tag_vec = Dense(tag_dim, activation='relu')(t_in)\n",
    "\n",
    "uf_embs = []\n",
    "for inp in uf_ins:\n",
    "    dim = vocab[inp.name]\n",
    "    emb = Embedding(input_dim=dim, output_dim=user_feat_dim)(inp)\n",
    "    uf_embs.append(Flatten()(emb))\n",
    "uf_vec = Concatenate()(uf_embs) if uf_embs else None\n",
    "\n",
    "# GMF branch\n",
    "gmf = Multiply()([u_emb, i_emb])\n",
    "\n",
    "# MLP branch\n",
    "mlp_inputs = [u_emb, i_emb, tag_vec] + ([uf_vec] if uf_vec is not None else [])\n",
    "x = Concatenate()(mlp_inputs)\n",
    "for units in [128, 64]:\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "# Output\n",
    "combined = Concatenate()([gmf, x])\n",
    "out = Dense(1, activation='sigmoid')(combined)\n",
    "model = Model(inputs=[u_in, i_in, t_in] + uf_ins, outputs=out)\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.Huber(delta=1.0))\n",
    "\n",
    "# Train the model\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, restore_best_weights=True\n",
    ")\n",
    "model.fit(train_ds, epochs=5, validation_data=test_ds, verbose=1, callbacks=[EarlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b70faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aniss/Documents/clone/reco/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('models/NeuMF.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, df_test, df_train, user_feat, k=10):\n",
    "    item_popularity = Counter(df_train['video_id'])\n",
    "    total_items = len(item_popularity)\n",
    "\n",
    "    all_user_ids = df_test['user_id'].unique()\n",
    "    mae_list = []\n",
    "    rmse_list = []\n",
    "    ndcg_list = []\n",
    "    novelty_list = []\n",
    "    tag_diversity_list = []\n",
    "    avg_popularity_list = []\n",
    "\n",
    "    for user_id in all_user_ids:\n",
    "        user_df = df_test[df_test['user_id'] == user_id]\n",
    "        if user_df.empty:\n",
    "            continue\n",
    "\n",
    "        true_watch_ratios = {row['video_id']: row['watch_ratio'] for _, row in user_df.iterrows()}\n",
    "        if all(v == 0 for v in true_watch_ratios.values()):\n",
    "            continue\n",
    "\n",
    "        user_inputs = {\n",
    "            'user_id': np.full(len(user_df), user_id, dtype='int32'),\n",
    "            'video_id': user_df['video_id'].values.astype('int32'),\n",
    "            'tag_multi_hot': np.array(user_df['tag_multi_hot'].tolist(), dtype='float32'),\n",
    "        }\n",
    "\n",
    "        for col in user_feat.columns:\n",
    "            if col != 'user_id':\n",
    "                val = user_df[col].values.astype('int32')\n",
    "                user_inputs[col] = val\n",
    "\n",
    "        preds = np.expm1(model.predict(user_inputs, verbose=0)).flatten()\n",
    "\n",
    "        ranked_indices = np.argsort(-preds)\n",
    "        ranked_items = user_df['video_id'].values[ranked_indices]\n",
    "        top_k_items = ranked_items[:k]\n",
    "        top_k_preds = preds[ranked_indices][:k]\n",
    "\n",
    "        # Get the true watch ratios for the top_k items\n",
    "        top_k_true = np.array([true_watch_ratios.get(item, 0.0) for item in top_k_items])\n",
    "\n",
    "        # # MAE@k and RMSE@k\n",
    "        abs_errors = np.abs(top_k_true - top_k_preds)\n",
    "        sq_errors = (top_k_true - top_k_preds) ** 2\n",
    "\n",
    "        mae = np.mean(abs_errors)\n",
    "        rmse = np.sqrt(np.mean(sq_errors))\n",
    "\n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "        # NDCG@k\n",
    "        relevance = [true_watch_ratios.get(item, 0.0) for item in ranked_items[:k]]\n",
    "        ndcg = ndcg_score([relevance], [top_k_preds])\n",
    "        ndcg_list.append(ndcg)\n",
    "\n",
    "        # Novelty@k\n",
    "        novelty = -np.mean([np.log2(item_popularity[item] / total_items + 1e-10) for item in top_k_items])\n",
    "        novelty_list.append(novelty)\n",
    "\n",
    "        # Tag diversity@k\n",
    "        tag_vectors = np.array([user_df[user_df['video_id'] == item]['tag_multi_hot'].values[0] for item in top_k_items])\n",
    "        tag_union = np.sum(np.any(tag_vectors, axis=0))\n",
    "        tag_diversity = tag_union / tag_vectors.shape[1]\n",
    "        tag_diversity_list.append(tag_diversity)\n",
    "\n",
    "        # Popularity@k\n",
    "        top_k_popularity = user_df.iloc[ranked_indices[:k]]['popularity_score'].values\n",
    "        avg_popularity = np.mean(top_k_popularity)\n",
    "        avg_popularity_list.append(avg_popularity)\n",
    "\n",
    "    print(f'MAE@{k}: {np.mean(mae_list):.4f}')\n",
    "    print(f'RMSE@{k}: {np.mean(rmse_list):.4f}')\n",
    "    print(f'NDCG@{k}: {np.mean(ndcg_list):.4f}')\n",
    "    print(f'Novelty@{k}: {np.mean(novelty_list):.4f}')\n",
    "    print(f'Tag Diversity@{k}: {np.mean(tag_diversity_list):.4f}')\n",
    "    print(f'Average Popularity@{k}: {np.mean(avg_popularity):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c611a4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE@10: 0.8108\n",
      "RMSE@10: 1.1460\n",
      "NDCG@10: 0.8656\n",
      "Novelty@10: 3.3277\n",
      "Tag Diversity@10: 0.2522\n",
      "Average Popularity@10: 1.0001\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, df_test, df_train, user_feat, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0948f",
   "metadata": {},
   "source": [
    "# Tag Weights Based on Watch Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1015400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode tags (0-30) → multi-hot vector\n",
    "item_cat['feat'] = item_cat['feat'].apply(literal_eval)\n",
    "tags_exploded = small_df[['video_id', 'watch_ratio']].merge(item_cat, on='video_id')\n",
    "tags_exploded = tags_exploded.explode('feat')\n",
    "tags_exploded['feat'] = pd.to_numeric(tags_exploded['feat'], errors='coerce')\n",
    "tag_watch_means = tags_exploded.groupby('feat')['watch_ratio'].mean()\n",
    "tag_weights = tag_watch_means\n",
    "tag_weights = tag_weights.reindex(range(31), fill_value=0).values  \n",
    "mlb = MultiLabelBinarizer(classes=list(range(31)))\n",
    "tag_matrix = mlb.fit_transform(item_cat['feat'])\n",
    "tag_matrix = tag_matrix * tag_weights \n",
    "tag_df = pd.DataFrame(tag_matrix, columns=[f'tag_{i}' for i in mlb.classes_])\n",
    "item_cat = pd.concat([item_cat[['video_id']], tag_df], axis=1)\n",
    "\n",
    "# Encode any string user features to integer codes\n",
    "for col in user_feat.columns:\n",
    "    if col != 'user_id' and user_feat[col].dtype == 'object':\n",
    "        user_feat[col], _ = pd.factorize(user_feat[col])\n",
    "\n",
    "df_train = big_df.merge(item_cat, on='video_id').merge(user_feat, on='user_id')\n",
    "df_test = small_df.merge(item_cat, on='video_id').merge(user_feat, on='user_id')\n",
    "\n",
    "# Number of videos watched by each user\n",
    "user_inter_counts = df_train.groupby(\"user_id\")[\"video_id\"].count()\n",
    "user_inter_counts.name = \"User Interactions\"\n",
    "\n",
    "# Number of times each video has been watched\n",
    "video_inter_counts = df_train.groupby(\"video_id\")[\"user_id\"].count()\n",
    "video_inter_counts.name = \"Video Interactions\"\n",
    "big_watch_ratio = df_train.watch_ratio\n",
    "\n",
    "df_train = df_train[\n",
    "    (df_train['user_id'].isin(user_inter_counts[user_inter_counts >= 248].index)) &\n",
    "    (df_train['video_id'].isin(video_inter_counts[video_inter_counts >= 1].index)) &\n",
    "    (df_train['watch_ratio'] > 0) &\n",
    "    (df_train['watch_ratio'] <= big_watch_ratio.quantile(0.75))\n",
    "]\n",
    "\n",
    "df_train['watch_ratio_log'] = np.log1p(df_train['watch_ratio'])\n",
    "df_test['watch_ratio_log'] = np.log1p(df_test['watch_ratio'])\n",
    "\n",
    "\n",
    "# Build tag_multi_hot list column and cast types\n",
    "tag_cols = [f'tag_{i}' for i in range(31)]\n",
    "for df in (df_train, df_test):\n",
    "    df['tag_multi_hot'] = df[tag_cols].values.tolist()\n",
    "    df.fillna(0, inplace=True)\n",
    "    df['user_id'] = df['user_id'].astype('int32')\n",
    "    df['video_id'] = df['video_id'].astype('int32')\n",
    "    for col in user_feat.columns:\n",
    "        if col != 'user_id':\n",
    "            df[col] = df[col].astype('int32')\n",
    "\n",
    "# Prepare tf.data Dataset\n",
    "def df_to_dataset(df, shuffle=False, batch_size=1024):\n",
    "    labels = df['watch_ratio_log'].values.astype('float32')\n",
    "    inputs = {col: df[col].values for col in ['user_id','video_id'] + [c for c in user_feat.columns if c!='user_id']}\n",
    "    inputs['tag_multi_hot'] = np.array(df['tag_multi_hot'].tolist(), dtype='float32')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(labels))\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = df_to_dataset(df_train, shuffle=True)\n",
    "test_ds  = df_to_dataset(df_test)\n",
    "\n",
    "# Determine global vocab sizes\n",
    "vocab = {}\n",
    "for col in ['user_id','video_id'] + [c for c in user_feat.columns if c!='user_id']:\n",
    "    mx = max(df_train[col].max(), df_test[col].max())\n",
    "    vocab[col] = int(mx) + 1\n",
    "\n",
    "K = 64; tag_dim = 16; user_feat_dim = 8\n",
    "\n",
    "# Inputs\n",
    "u_in = Input(shape=(), name='user_id', dtype='int32')\n",
    "i_in = Input(shape=(), name='video_id', dtype='int32')\n",
    "t_in = Input(shape=(31,), name='tag_multi_hot', dtype='float32')\n",
    "uf_ins = [Input(shape=(), name=col, dtype='int32') \n",
    "          for col in user_feat.columns if col!='user_id']\n",
    "\n",
    "# Embeddings\n",
    "u_emb = Flatten()(Embedding(input_dim=vocab['user_id'], output_dim=K)(u_in))\n",
    "i_emb = Flatten()(Embedding(input_dim=vocab['video_id'], output_dim=K)(i_in))\n",
    "\n",
    "tag_vec = Dense(tag_dim, activation='relu')(t_in)\n",
    "\n",
    "uf_embs = []\n",
    "for inp in uf_ins:\n",
    "    dim = vocab[inp.name]\n",
    "    emb = Embedding(input_dim=dim, output_dim=user_feat_dim)(inp)\n",
    "    uf_embs.append(Flatten()(emb))\n",
    "uf_vec = Concatenate()(uf_embs) if uf_embs else None\n",
    "\n",
    "# GMF branch\n",
    "gmf = Multiply()([u_emb, i_emb])\n",
    "\n",
    "# MLP branch\n",
    "mlp_inputs = [u_emb, i_emb, tag_vec] + ([uf_vec] if uf_vec is not None else [])\n",
    "x = Concatenate()(mlp_inputs)\n",
    "for units in [128, 64]:\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "# Output\n",
    "combined = Concatenate()([gmf, x])\n",
    "out = Dense(1, activation='sigmoid')(combined)\n",
    "model_w = Model(inputs=[u_in, i_in, t_in] + uf_ins, outputs=out)\n",
    "model_w.compile(optimizer='adam', loss=tf.keras.losses.Huber(delta=1.0))\n",
    "\n",
    "# 8. Train the model\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, restore_best_weights=True\n",
    ")\n",
    "model_w.fit(train_ds, epochs=5, validation_data=test_ds, verbose=1, callbacks=[EarlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365ee64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aniss/Documents/clone/reco/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_w.save('models/NeuMF_w.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47bbceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE@10: 0.6123\n",
      "RMSE@10: 0.9089\n",
      "NDCG@10: 0.8577\n",
      "Novelty@10: 3.2139\n",
      "Tag Diversity@10: 0.2467\n",
      "Average Popularity@10: 0.9941\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_w, df_test, df_train, user_feat, k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
